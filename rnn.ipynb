{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 123-D feature vectors\n",
    "# 61 phoneme labels mapped to 39 classes\n",
    "num_epochs = 100\n",
    "total_series_length = 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4\n",
    "num_classes = 61\n",
    "echo_step = 3\n",
    "batch_size = 5\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length\n",
    "dims = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_FILES = \"feature_files\"\n",
    "FEATURE_LABELS = \"feature_labels\"\n",
    "TRAIN = \"TRAIN\"\n",
    "TEST = \"TEST\"\n",
    "\n",
    "def get_data():\n",
    "    x = np.array([])\n",
    "    y = np.array([])\n",
    "    # GET TRAINING DATA\n",
    "    for file_name in os.listdir(FEATURE_FILES + \"/\" + TRAIN):\n",
    "        x_s = np.load(os.path.join(FEATURE_FILES, TRAIN, file_name))\n",
    "        x = np.vstack((x, x_s)) if x.size else x_s\n",
    "        break\n",
    "\n",
    "    for file_name in os.listdir(FEATURE_LABELS + \"/\" + TRAIN):\n",
    "        y_s = np.load(os.path.join(FEATURE_LABELS, TRAIN, file_name))\n",
    "        y = np.vstack((y, y_s)) if y.size else y_s\n",
    "        break\n",
    "    \n",
    "    # x = x.reshape((batch_size, -1, dims))\n",
    "    return x, y\n",
    "    \n",
    "x, y = get_data()\n",
    "\n",
    "# x.shape should be (batch_size, max_time_step, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "def generate_data():\n",
    "    x = np.array(np.random.choice(2, total_series_length, p=[0.5, 0.5]))\n",
    "    y = np.roll(x, echo_step)\n",
    "    y[0:echo_step] = 0\n",
    "    \n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    x = x.reshape((batch_size, -1, 1))  # 3-D because tf.nn.dynamic_rnn only takes 3-D tensors\n",
    "    y = y.reshape((batch_size, -1))\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "def generate_sine():\n",
    "    x = np.linspace(0, 100, total_series_length)\n",
    "    y = np.cos(x)\n",
    "    \n",
    "    x = x.reshape((batch_size, -1, 1))  # 3-D because tf.nn.dynamic_rnn only takes 3-D tensors\n",
    "    y = y.reshape((batch_size, -1))\n",
    "    return x, y\n",
    "\n",
    "x, y = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [batch_size, truncated_backprop_length, dims], name=\"input_placeholder\")\n",
    "y = tf.placeholder(tf.int32, [batch_size, truncated_backprop_length], name=\"label_placeholder\")\n",
    "\n",
    "# LSTM\n",
    "# cell_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "# hidden_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "# init_state = tf.contrib.rnn.LSTMStateTuple(cell_state, hidden_state)\n",
    "\n",
    "# RNN\n",
    "init_state = tf.placeholder(tf.float32, [batch_size, state_size])\n",
    "\n",
    "\n",
    "W = tf.Variable(np.random.rand(state_size, num_classes), dtype=tf.float32) # W is 4x2\n",
    "b = tf.Variable(np.zeros((1,num_classes)), dtype=tf.float32)# b is 1x2\n",
    "\n",
    "# Unpack columns\n",
    "labels_series = tf.unstack(y, axis=1)\n",
    "\n",
    "# Forward passes\n",
    "\n",
    "# RNN\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "\n",
    "#LSTM\n",
    "# cell = tf.contrib.rnn.BasicLSTMCell(state_size, state_is_tuple=True)\n",
    "\n",
    "states_series, current_state = tf.nn.dynamic_rnn(cell=cell, inputs=x, initial_state=init_state)\n",
    "\n",
    "logits_series = [tf.matmul(state, W) + b for state in tf.unstack(states_series, axis=1)]\n",
    "predictions_series = [tf.nn.softmax(logits) for logits in logits_series]\n",
    "\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-3c3c6af19978>:2: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "New data, epoch 0\n",
      "Step 0 Loss 3.92492\n",
      "Step 100 Loss 0.0108291\n",
      "Step 200 Loss 0.00532531\n",
      "Step 300 Loss 0.00354094\n",
      "Step 400 Loss 0.00265346\n",
      "Step 500 Loss 0.00212172\n",
      "Step 600 Loss 0.00176774\n",
      "New data, epoch 1\n",
      "Step 0 Loss 0.0972658\n",
      "Step 100 Loss 0.00140235\n",
      "Step 200 Loss 0.00122597\n",
      "Step 300 Loss 0.00109758\n",
      "Step 400 Loss 0.000994783\n",
      "Step 500 Loss 0.000909034\n",
      "Step 600 Loss 0.000837095\n",
      "New data, epoch 2\n",
      "Step 0 Loss 0.101029\n",
      "Step 100 Loss 0.000752752\n",
      "Step 200 Loss 0.000695321\n",
      "Step 300 Loss 0.000651719\n",
      "Step 400 Loss 0.00061374\n",
      "Step 500 Loss 0.000580023\n",
      "Step 600 Loss 0.00055\n",
      "New data, epoch 3\n",
      "Step 0 Loss 0.102703\n",
      "Step 100 Loss 0.000515659\n",
      "Step 200 Loss 0.000486588\n",
      "Step 300 Loss 0.000464284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda2/envs/rnn/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/anaconda2/envs/rnn/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/anaconda2/envs/rnn/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/anaconda2/envs/rnn/lib/python2.7/inspect.py\", line 1051, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/anaconda2/envs/rnn/lib/python2.7/inspect.py\", line 1011, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/anaconda2/envs/rnn/lib/python2.7/inspect.py\", line 453, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/anaconda2/envs/rnn/lib/python2.7/inspect.py\", line 499, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/anaconda2/envs/rnn/lib/python2.7/posixpath.py\", line 375, in realpath\n",
      "    path, ok = _joinrealpath('', filename, {})\n",
      "  File \"/anaconda2/envs/rnn/lib/python2.7/posixpath.py\", line 399, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/anaconda2/envs/rnn/lib/python2.7/posixpath.py\", line 68, in join\n",
      "    if b.startswith('/'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/anaconda2/envs/rnn/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/rnn/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1826\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/rnn/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1412\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/rnn/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             )\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/envs/rnn/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        x1,y1 = generate_sine()\n",
    "        # RNN\n",
    "        _current_state = np.zeros((batch_size, state_size))\n",
    "        \n",
    "        # LSTM\n",
    "#         _current_cell_state = np.zeros((batch_size, state_size))\n",
    "#         _current_hidden_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * truncated_backprop_length\n",
    "            end_idx = start_idx + truncated_backprop_length\n",
    "\n",
    "            batchX = x1[:,start_idx:end_idx]\n",
    "            batchY = y1[:,start_idx:end_idx]\n",
    "            \n",
    "            _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "                [total_loss, train_step, current_state, predictions_series],\n",
    "                feed_dict={\n",
    "                    x:batchX,\n",
    "                    y:batchY,\n",
    "                    # RNN\n",
    "                    init_state: _current_state,\n",
    "                    \n",
    "                    # LSTM\n",
    "#                     cell_state: _current_cell_state,\n",
    "#                     hidden_state: _current_hidden_state\n",
    "                })\n",
    "\n",
    "            loss_list.append(_total_loss)\n",
    "\n",
    "            if batch_idx%100 == 0:\n",
    "                print(\"Step\",batch_idx, \"Loss\", _total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
